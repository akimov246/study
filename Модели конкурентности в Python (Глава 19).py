# Термины
'''
Конкурентность - способность обрабатывать несколько задач, чередуя выполнение или параллельно (если это возможно),
так что каждая задача в конечном итоге успешно доходит до конца или завершается с ошибкой. Одноядерный процессор
допускает конкурентность, если работает под управлением планировщика ОС, который чередует выполнение ожидающих задач.
Встречается также название многозадачность.

Параллелизм - способность выполнять несколько вычислений одновременно. Для этого необходим многоядерный процессор,
несколько процессоров, графический процессор или кластер из нескольких компьютеров.

Единица выполнения - общий термин для объектов, выполняющих код конкурентно, каждый из которых имеет независимые от других
состояния и стек вызовов. Python поддерживает три вида единиц выполнения: процессы, потоки и сопрограммы.

Процесс - экземпляр компьютерной программы во время ее выполнения, которому выделены память и квант процессорного времени.
Современные операционные системы для настольных компьютеров без труда управляют сотнями конкурентных процессов,
при этом каждый процесс изолирован в собственном адресном пространстве. Процессы взаимодействуют посредством каналов,
советов или отображенных на память файлов - все они могут передавать только "голые" байты. Чтобы передать объект Python из
одного процесса в другой, его необходимо сериализовать в виде последовательности байтов. Это дорого, и не все объекты
допускают сериализацию. Процесс может порождать подпроцессы, или дочерние процессы. Они изолированны как друг от друга,
так и от родительского процесса. Процессы допускают вытесняющую многозадачность: планировщик ОС периодически вытесняет, т.е.
приостанавливает процесс, чтобы дать возможность поработать остальным. Это означает, что зависший процесс не может подвесить
всю системы - теоретически.

Поток - единица выполнения внутри одного процесса. Сразу после запуска процесс содержит один - главный - поток.
Вызывая системные API, процесс может создавать дополнительные потоки, которые будут работать конкурентно.
Потоки внутри одного процесса разделяют общее пространство памяти, в которой находятся активные объекты Python.
Это позволяет потокам совместно использовать данные, но может приводить к повреждению данных, если сразу несколько
потоков пытаются обновить один и тот же объект. Как и процессы, потоки допускают вытесняющую многозадачность под
управлением планировщика ОС. Поток потребляет меньше ресурсов, чем процесс, для выполнения одной и той же работы.

Сопрограмма - функция, которая может приостановить свое выполнение и продолжить позже. В Python классиеческие сопрограммы
стоятся на основе генераторных функций, а платформенные определяются с помощью ключевых слов async def.
В Python сопрограммы обычно исполняются в одном потоке под управлением цикла событий, который работает в том же потоке.
Такие каркасы асинхронного программирования, как asyncio, Cyrio или Trio, предоставляют цикл событий и поддерживающие библиотеки
для реализации неблокирующего ввода-вывода на основе сопрограмм. Сопрограммы поддерживают кооперативную многозадачность:
каждая сопрограмма должна явно уступать процессор с помощью ключевого слова yield или await, чтобы другие части программы
могли работать конкурентно (но не параллельно). Это означает, что любой блокирующий код внутри сопрограммы блокирует
выполнение цикла событий всех остальных сопрограмм - в отличие от вытесняющей многозадачности, которую поддерживают процессы
и потоки. С другой стороны, сопрограммы потребляют меньше ресурсов по сравнению с процессами и потоками, выполняющими ту же работу.

Очередь - струтура данных, позволяющая помещать и извлекать элементы, обычно в порядке FIFO: первым пришел, первым ушел.
Очереди дают возможность единицам выполнения обмениваться данными и управляющими сообщениями, например кодами ошибок
и сигналами завершения. Реализация очереди зависит от модели конкурентности: пакет queue в стандартной библиотеке Python
предоставляет классы очередей для поддержки потоков, тогда как пакеты multiprocessing и asyncio реализуют собственные классы
очередей. Пакеты queue и asyncio включают также очереди, обсуживаемые не в порядке FIFO: LifeQueue и PriorityQueue.

Блокировка - объект, который единицы выполнения могут использовать для синхронизации своих действий, чтобы избежать
повреждения данных. Во время обновления разделяемой структуры данных исполняемый код должен удерживать ассоциированную
блокировку. Это служит для остальных частей прогрммы сигналом, что нужно подождать, пока блокировка освободится, и только
потом обращаться к той же структуре данных. Простейший вид блокировки называется мьютексом (mutual exclusion - взаимное
исключение). Реализация блокировки зависит от модели конкурентности.

Состязание - спор за ограниченный ресурс. Состязание возникает, когда несколько единиц выполнения пытаются обратиться к
разделяемому ресурсу, например блокировке или хранилищу. Бывает также состязание за процессор, когда счетные процессы
или потоки должны ждать, пока планировщик ОС выделит им долю процессорного времени.
'''

# Процессы, потоки и знаменитая блокировка GIL в Python
import math
import multiprocessing
import queue

'''
Ниже описано, как вышеописанные термины применяются в контексте программирования на Python.

1. Каждый экземпляр интерпретатора Python является процессом. Дополнительные процессы Python можно запускать с помощью
библиотек multiprocessing или concurrent.futures. Библиотека subprocess предназначена для запуска процессов, в которых
будут исполняться внешние программы, написанные на любом языке.

2. Интерпретатор Python использует единственный поток, в котором выполняется и пользовательская программа и сборщик мусора.
Для запуска дополнительных потоков предназначены библиотеки threading и concurrent.futures.

3. Доступ к счетчикам ссылок на объекты и другим внутренним структурам интерпретатора контролируется глобальной блокировкой
интерпретатора (Global Interpreter Lock - GIL). Только один поток Python может удерживать GIL в каждый момент времени.
Это означает, что только один поток может выполнять Python-код, и от числа процессорных ядер это не зависит. 

4. Чтобы помешать потоку Python удерживать GIL бесконечно, итерпретатор байт-кода Python периодически (по умолчанию раз 
в 5 миллисекунд) приостанавливает текущий поток и тем самым освобождает GIL. Поток может попытаться снова захватить GIL, но
если его ждут другие потоки, то планировщик ОС, возможно, выберет один из них.

5. Программист, пишущий на Python, не может управлять GIL. Но встроенная функция или расширение, написанное на C или на любом
другом языке, имеющем интерфейс к Python на уровне C API, может освободить GIL во время выполнения длительной задачи.

6. Любая стандартная библиотечная функция Python, делающая системный вызов, освобождает GIL. Сюда относятся все функции,
выполняющие дисковый ввод-вывод, сетевой ввод-вывод, а так же time.sleep(). Многие счетные функции в библиотеках 
NumPy/SciPy, а также функции сжатия и распаковки из модулей zlib и bz2 также освобождают GIL.

7. Расширения, интегрированные на уровне интерфейса между Python и C, могут тоже запускать потоки, не управляемые Python, 
на которые действие GIL не распространяется. Такие свободные от GIL потоки в общем случае не могут изменять объекты Python,
но могут читать и записывать память объектов, поддерживающих протокол буфера, например bytearray, array.array и массивы NumPy.

8. Влияние GIL на сетевое программирование с помощью потоков Python сравнительно невелико, потому что функции ввода-вывода
освобождают GIL, а чтение или запись в сеть всегда подразумевает высокую задержку по сравнению с чтением-записью в память.
Следовательно, каждый отдельный поток все равно тратит много времени на ожидание, так что их выполнение можно чередовать без
заметного снижения общей пропускной способности.

9. Состязание за GIL замедляет работу счетных потоков в Python. В таких случаях последовательный однопоточный код проще и быстрее.

10. Для выполнения счетного Python-кода на нескольких ядрах нужно использовать несколько процессов Python. 
'''

# Конкурентная программа Hello World
# Анимированный индикатор с потоками

import itertools
import time

from threading import Thread, Event

def spin_threading(msg: str, done: Event) -> None:
    for char in itertools.cycle(r'\/\-'):
        status = f'\r{char} {msg}'
        print(status, end='')
        if done.wait(.3):
            '''Функция Event.wait(timeout=None) возвращает True, когда другой поток установил событие;
            если же истек тайм-аут timeout, то он возвращает False. Тайм-аут .1s означает, что анимация
            производится 10 кадров в секунду.'''
            blanks = ' ' * len(status)
            print(f'\r{blanks}\r', end='')
            break
        blanks = ' ' * len(status)
        print(f'\r{blanks}\r', end='')

def slow_threading() -> int:
    '''Вызывается из главного потока. Представьте, что это вызов медленного API по сети.
    Вызов sleep блокирует главный поток, но GIL при этом освобождается, поэтому поток индикатора продолжает работать.'''
    time.sleep(2)
    #is_prime(5_000_111_000_222_021)
    return 42

'''
Класс threading.Event - самый простой из имеющихся в Python механизмов сигнализации для координации потоков.
В экзампляре Event имеется внутренний булевый флаг, который первоначально равен False. Вызов Event.set() устанавливает 
этот флаг в True. Если флаг равен False, то поток, вызвавший Event.wait(), блокируется до тех пор, пока какой-нибудь 
другой поток не вызовет Event.set(), и в этот момент Event.wait() возвращает True. Если функции Event.wait(s) передан
тайм-аут в секундах, то по истеении тайм-аута этот вызов вернет False (или True, если раньше какой-то другой поток
вызовет Event.set()).
'''

def supervisor_threading() -> int: # Возврашает результат slow()
    done = Event()
    spinner = Thread(target=spin_threading, args=('threading thinking!', done)) # Чтобы задать новый экземплятр Thread, задайте функцию в именованном
                                                            # аргументе target, а необходимые ей позиционные аргументы передавайте
                                                            # в кортеже args
    print(f'spinner object: {spinner}') # Отобразить объект spinner
    spinner.start() # Запустить поток spinner
    result = slow_threading() # Вызвать функцию slow(), которая блокирует поток main. Тем временем второй поток выполняет анимацию индикатора.
    done.set() # Установить флаг Event в True; в результате чего произойдет выход из цикла for в функции spin
    spinner.join() # Ждать завершения потока spinner
    return result

def main_threading() -> None:
    result = supervisor_threading()
    print(f'Answer: {result}')

if __name__ == '__main__':
    main_threading()

# Индикатор с процессами

import itertools
import time
from multiprocessing import Process, Event, synchronize

def spin_multiprocessing(msg: str, done: synchronize.Event) -> None:
    for char in itertools.cycle('\|/-'):
        status = f'\r{msg} {char}'
        print(status, end='')
        if done.wait(0.3):
            blanks = ' ' * len(status)
            print(f'\r{blanks}\r', end='')
            break
        blanks = ' ' * len(status)
        print(f'\r{blanks}\r', end='')

def slow_multiprocessing():
    time.sleep(2)
    #is_prime(5_000_111_000_222_021)
    return 42

def supervisor_multiprocessing() -> int:
    done = multiprocessing.Event()
    spinner = Process(target=spin_multiprocessing, args=('multiprocessing thinking', done))
    print(f'spinner object: {spinner}')
    spinner.start()
    result = slow_multiprocessing()
    done.set()
    spinner.join()
    return result

def main_multiprocessing():
    result = supervisor_multiprocessing()
    print(f'Answer: {result}')

if __name__ == '__main__':
    main_multiprocessing()

# Индикатор с сопрограммами

import asyncio
import itertools

def main_asyncio() -> None:
    result = asyncio.run(supervisor_asyncio())
    '''Функция asyncio.run запускает цикл событий, активирующий сопрограмму, которая в конечном итоге приведет
    в дейстие и другие сопрограммы. Функция main остается блокированной, пока supervisor_asyncio не вернет управление.
    Значение, возвращенное supervisor_asyncio, станет значением, возвращенным asyncio.run.'''
    print(f'Answer: {result}')

async def supervisor_asyncio() -> int: # платформенная сопрограмма (ключевые слово async def)
    spinner = asyncio.create_task(spin_asyncio('asyncio thinking')) # Планирует выполнение spin_asyncio сразу после
                                                                    # возврата экзампляра asyncio.Task
    print(f'spinner object: {spinner}')
    result = await slow_asyncio() # Ключевое слово await вызывает slow_asyncio, блокирующую supervisor_asyncio до возврата из slow_asyncio.
                          # Значение, возвращенное slow_asyncio, присваивается переменной result.
    spinner.cancel() # Метод Task.cancel возбуждает исключение CancelledError внути сопрограммы spin_asyncio.
    return result

async def spin_asyncio(msg: str) -> None: # Нам не нужен аргумент Event
    for char in itertools.cycle('\|/-'):
        status = f'\r{msg} {char}'
        print(status, end='')
        try:
            await asyncio.sleep(0.3) # Использовать asyncio.sleep() вместо time.sleep(), чтобы приостановить выполнение
                                     # без блокировки других сопрограмм
        except asyncio.CancelledError:
            '''Когда вызывается метод cancel() объекта Task, управляющего этой сопрограммой, возбуждается исключение CancelledError.
            Время выходить из цикла.'''
            blanks = ' ' * len(status)
            print(f'\r{blanks}\r', end='')
            break
    blanks = ' ' * len(status)
    print(f'\r{blanks}\r', end='')

async def slow_asyncio() -> int:
    await asyncio.sleep(2) # Сопрограмма slow_asyncio также использует await asyncio.sleep() вместо time.sleep().
    #await is_prime_async(5_000_111_000_222_021)
    # Эксперимент: ломаем индикатор ради озарения
    #time.sleep(1)
    return 42

if __name__ == '__main__':
    main_asyncio()

'''
asyncio.run(coro()) вызывается из регулярной функции для управления объектом сопрограммы, который обычно является точкой
входа в весь асинхронный код программы. Этот вызов блокирует выполнение, пока coro() не вернет управление.
Функция run() возвращает значение, возвращенное coro().

asyncio.create_task(coro()) вызывается из сопрограммы, чтобы запланировать выполнение другой сопрограммы. Этот вызов
не приостанавливает текущую сопрограмму. Он возвращает экзампляр Task - объект, который обертывает объект сопрограммы
и предоставляет методы для управления ей и опроса ее состояния.

await coro() вызывается из сопрограммы, чтобы передать управление объекту сопрограммы, возвращенному coro().
Этот вызов приостанавливает текущую сопрограмму до возврата из coro(). Значением выражения await является значение,
возвращенное coro().

!!! Вызов сопрограммы как coro() сразу же возвращает объект сопрограммы, но не выполняет тело функции coro.
Активация тел сопрограммы - задача цикла событий.

!!! Никогда не используйте time.sleep() в сопрограммах asyncio, если не хотите приостановить всю программу в целом.
Если сопрограмма хочет протратить некоторое время, ничего не делая, она должна вызвать await asyncio.sleep().
Так она уступит управление циклу событий asyncio, который может дать поработать другим ожидающим сопрограммам.
'''

# Истинное влияние GIL

def is_prime(n: int) -> bool:
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False
    root = math.isqrt(n)
    for i in range(3, root + 1, 2):
        if n % i == 0:
            return False
    return True

# Асинхронный вариант функции, чтобы крутился индикатор (код при этом будет работать заметно медленнее)
async def is_prime_async(n: int) -> bool:
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False
    root = math.isqrt(n)
    for i in range(3, root + 1, 2):
        if n % i == 0:
            return False
        if i % 100_000 == 1:
            await asyncio.sleep(0)
    return True

'''
Использование await asyncio.sleep(0) следует рассматривать как временную меру перед рефакторингом асинхронного кода
с целью делегирования длительных вычислений другому процессу.
'''

# Доморощенный пул процессов

NUMBERS = (2,
           142702110479723,
           299593572317531,
           3333333333333301,
           3333333333333333,
           3333335652092209,
           4444444444444423,
           4444444444444444,
           4444444488888889,
           5555553133149889,
           5555555555555503,
           5555555555555555,
           6666666666666666,
           6666666666666719,
           6666667141414921,
           7777777536340681,
           7777777777777753,
           7777777777777777,
           9999999999999917,
           9999999999999999)

# Последовательная проверка на простоту (эталон)
from time import perf_counter
from dataclasses import dataclass
from typing import NamedTuple

# @dataclass
# class Result:
#     prime: bool
#     elapsed: float
#
#     def __iter__(self):
#         return iter((self.prime, self.elapsed))
class Result(NamedTuple):
    prime: bool
    elapsed: float

def check(n: int) -> Result:
    t0 = perf_counter()
    prime = is_prime(n)
    return Result(prime, perf_counter() - t0)

def main() -> None:
    print(f'Checking {len(NUMBERS)} numbers sequentially:')
    t0 = perf_counter()
    for n in NUMBERS:
        prime, elapsed = check(n)
        label = 'P' if prime else ' '
        print(f'{n:16} {label} {elapsed:9.6f}s')

    elapsed = perf_counter() - t0
    print(f'Total time: {elapsed:.2f}s')

if __name__ == '__main__':
    #main()
    pass

# Проверка на простоту. Решение на основе процессов
import sys
from time import perf_counter
from typing import NamedTuple, TypeAlias
from multiprocessing import Process, SimpleQueue, cpu_count
from multiprocessing import queues # Используется для аннотаций типов (напрмиер queues.SimpleQueue)

class PrimeResult(NamedTuple):
    n: int
    prime: bool
    elapsed: float

JobQueue: TypeAlias = queues.SimpleQueue[int]
ResultQueue: TypeAlias = queue.SimpleQueue[PrimeResult]

def check(n: int) -> PrimeResult:
    t0 = perf_counter()
    res = is_prime(n)
    return PrimeResult(n, res, perf_counter() - t0)

def worker(jobs: JobQueue, results: ResultQueue) -> None:
    '''worker получает очередь подлежащих проверке чисел и другую очередь, в которую будет помещать результаты'''
    while n := jobs.get(): # Число 0 использутеся, как сигнал исполнителю о необходимости завершиться.
        results.put(check(n)) # Инициировать проверку на простоту и поместить PrimeResult в очередь
    results.put(PrimeResult(0, False, 0.0)) # Отправить PrimeResult(0, False, 0.0) обратно, чтобы главный цикл знал, что
                                            # этот исполнитель работу закончил

def start_jobs(procs: int, jobs: JobQueue, results: ResultQueue) -> None:
    '''procs - количество процессов, которые будут параллельно проверять числа'''
    for n in NUMBERS:
        jobs.put(n) # Поместить подлежащее проверке числа в очередь jobs
    for _ in range(procs):
        proc = Process(target=worker, args=(jobs, results)) # Создать дочерние процессы для всех исполнителей.
                                                            # Каждый дочерний процесс будет исполнять цикл в собственном экземпляре
                                                            # функции worker, пока не извлечет 0 из очереди jobs
        proc.start() # Запустить все дочерние процессы
        jobs.put(0) # Поместить в очередь по одному значению 0 для каждого процесса, чтобы завершить их

def main() -> None:
    if len(sys.argv) < 2: # Если аргументы в коммандной строке не заданы, то положить количество процессов равным количеству
                          # процессорных ядер, в противном случае создать столько процессов, сколько указано в первом аргументе
        procs = cpu_count()
    else:
        procs = int(sys.argv[1])

    print(f'Checking {len(NUMBERS)} numbers with {procs} processes:')
    t0 = perf_counter()
    jobs: JobQueue = SimpleQueue()
    results: ResultQueue = SimpleQueue()
    start_jobs(procs, jobs, results) # Запустить proc процессов, которые будут выбирать данные из очереди jobs и помещать
                                     # результаты в results
    checked = report(procs, results) # Извлечь и отобразить результаты
    elapsed = perf_counter() - t0
    print(f'{checked} checks in {elapsed:.2f}s') # Показать количество проверенных чисел и общее затраченное время

def report(procs: int, results: ResultQueue) -> int:
    checked = 0 # Количество проверенных чисел
    procs_done = 0 # Количество выполненных процессов
    while procs_done < procs: # Цикл продолжается, пока не завершатся все дочерние процессы
        n, prime, elapsed = results.get() # Получить один PrimeResult. Вызов метода очереди .get() блокирует выполнение
                                          # до тех пор, пока в очереди не появится элемент.
        if n == 0: # Если n равно 0, то один процесс завершился; увеличить счетчик procs_done
            procs_done += 1
        else:
            checked += 1 # В противном случае увеличить счетчик checked и отобразить результаты
            label = 'P' if prime else ' '
            print(f'{n:16} {label} {elapsed:9.6f}s')
    return checked

if __name__ == '__main__':
    main()
